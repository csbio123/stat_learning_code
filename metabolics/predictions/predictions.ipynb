{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from io import StringIO\n",
    "from typing import Dict\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_pandas(text):\n",
    "    stringio = StringIO(text[1])\n",
    "    df = pd.read_csv(stringio).drop('Unnamed: 0', axis=1)\n",
    "    return get_keys(text[0]), df\n",
    "\n",
    "def get_keys(x):\n",
    "    try:\n",
    "        name = os.path.basename(x)\n",
    "        return \"\".join([s for s in name if s.isdigit()])\n",
    "    except (IndexError, KeyError):\n",
    "        return '', ''\n",
    "    \n",
    "def concat(x):\n",
    "    train = x[1][0][1]\n",
    "    train[\"train\"] = 1\n",
    "    \n",
    "    val = x[1][1][1]\n",
    "    val[\"train\"] = 0\n",
    "    \n",
    "    train = pd.concat([train, gene_expression_train_bc.value], axis=1)\n",
    "    val = pd.concat([val, gene_expression_validation_bc.value], axis=1)\n",
    "\n",
    "    \n",
    "    return pd.concat([train, val], axis=0, ignore_index=True)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_rdd = sc.wholeTextFiles(\"gs://conrad-project/validation_prediction/spark_input_data/validation_combat_9_03_18/*\", minPartitions=500)\n",
    "training_rdd = sc.wholeTextFiles(\"gs://conrad-project/validation_prediction/spark_input_data/train_combat_9_03_18/*\", minPartitions=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_expression_train = spark.read.option(\"header\", True).csv(\"gs://conrad-project/validation_prediction/spark_input_data/training_set_gene_expression.csv\").toPandas()\n",
    "gene_expression_validation = spark.read.option(\"header\", True).csv(\"gs://conrad-project/validation_prediction/spark_input_data/validation_set_gene_expression.csv\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4684\n",
      "4684\n"
     ]
    }
   ],
   "source": [
    "cols = [ \"gene_\" + c for c in gene_expression_train.columns.tolist()]\n",
    "cols[0] = \"name\"\n",
    "gene_expression_train.columns = cols\n",
    "print(len(set(cols)))\n",
    "\n",
    "cols = [ \"gene_\" + c for c in gene_expression_validation.columns.tolist()]\n",
    "cols[0] = \"name\"\n",
    "gene_expression_validation.columns = cols\n",
    "print(len(set(cols)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_expression_train_bc = sc.broadcast(gene_expression_train)\n",
    "gene_expression_validation_bc = sc.broadcast(gene_expression_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_rdd = validation_rdd.map(lambda x: string_to_pandas(x)).keyBy(lambda x: get_keys(x[0]))\n",
    "training_rdd = training_rdd.map(lambda x: string_to_pandas(x)).keyBy(lambda x: get_keys(x[0]))\n",
    "joined_rdd = training_rdd.join(validation_rdd, numPartitions=500).map(concat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = validation_rdd.take(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = joined_rdd.take(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast(data, target, features, clf):\n",
    "\n",
    "    data = data.apply(pd.to_numeric, errors=\"ignore\")\n",
    "    data[target] = np.log(data[target])\n",
    "    if data.shape[0] < 10:\n",
    "        return []\n",
    "\n",
    "    data = data.reset_index(drop=True)\n",
    "    data_train = data[data[\"train\"] == 1]\n",
    "    data_test  =  data[(data[\"train\"] == 0)]\n",
    "\n",
    "    data_train = data_train.replace([np.inf, -np.inf], np.nan)\n",
    "    data_test = data_test.replace([np.inf, -np.inf], np.nan)\n",
    "    data_train = data_train.dropna(subset=features+[target])\n",
    "    data_test = data_test.dropna(subset=features+[target])\n",
    "    \n",
    "    \n",
    "    importances = []\n",
    "    if data_test.shape[0] > 0:\n",
    "        num_training = data_train.shape[0]\n",
    "        df = pd.get_dummies(pd.concat([data_train, data_test])[features])\n",
    "\n",
    "        X_train = df.iloc[:num_training, :]\n",
    "        X_test = df.iloc[num_training:, :]\n",
    "\n",
    "        y_train = data_train[target].values.ravel()\n",
    "        clf.fit(X_train, y_train)\n",
    "        prediction = clf.predict(X_test)\n",
    "        data_test[\"prediction\"] = np.exp(prediction)\n",
    "        importances.append(clf.feature_importances_)\n",
    "        for r in range (0, 100):\n",
    "            np.random.shuffle(y_train)\n",
    "            clf.fit(X_train, y_train)\n",
    "            prediction = clf.predict(X_test)\n",
    "            importances.append(clf.feature_importances_)\n",
    "            data_test[\"prediction_{}\".format(r)] = np.exp(prediction)\n",
    "        return [data_test.filter(regex=\"prediction*\"), pd.DataFrame(importances)]\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestRegressor(n_estimators=100, criterion='mse', max_depth=None, min_samples_split=2,\n",
    "                                min_samples_leaf=1,\n",
    "                                min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, bootstrap=True,\n",
    "                                oob_score=True, n_jobs=-1, random_state=None,\n",
    "                                verbose=0, warm_start=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = joined_rdd.take(1)[0]\n",
    "features = test.drop(['BMI.catg', 'BMI.norm', 'name'], axis=1).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_rdd = joined_rdd.map(lambda x: forecast(x, \"BMI.norm\", features, clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = forecast_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_pred = []\n",
    "importances = []\n",
    "for i, p in enumerate(predictions):\n",
    "    pred = p[0]\n",
    "    impor = p[1]\n",
    "    pred[\"imputation_set\"] = i\n",
    "    impor[\"imputation_set\"] = i\n",
    "    importances.append(impor)\n",
    "    results_pred.append(pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_pred = pd.concat(results_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.concat(importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_pred.to_csv(\"/home/tomi/data/results_pred.scv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances.to_csv(\"/home/tomi/data/importances.scv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
